# MarkovChain
An implementation of Markov Chain multiplde different ways.
<ul>
  -<li>1) Open new_file_test_Markov.py</li><br/>
  -<li>2) Choose either you want an existing file (e) or a totally random one (r)</li><br/>
  -- <ul><li>(e): type big.txt or test.txt</li><br/>
  -- <li>(r): pick a number of words (it's better to pick any number greater than 1000)</li><br/></ul>
  -<li>3) Look at the output</li><br/>
</ul>
